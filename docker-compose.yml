version: '3.8'

services:
  # Telegram Bot Service (connects to existing Ollama)
  # This compose file is for a bot-only deployment, connecting to an external Ollama instance.
  # Ensure OLLAMA_HOST is correctly configured in your Portainer environment variables or .env file.
  telegram-bot:
    build: .
    container_name: deepthought-bot
    restart: unless-stopped
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - BOT_USERNAME=${BOT_USERNAME:-DeepthoughtBot}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://host.docker.internal:11434} # Connects to external Ollama
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama2}
      - MAX_TOKENS=${MAX_TOKENS:-2000}
      - TEMPERATURE=${TEMPERATURE:-0.7}
      - TIMEOUT=${TIMEOUT:-30}
      - DEFAULT_PROMPT=${DEFAULT_PROMPT}
      - BOT_CONFIG_DIR=/app/data # Set the config directory inside the container
      - BOT_APP_SOURCE_DIR=/app # Set the application source directory
    volumes:
      - bot_logs:/app/logs
      - /opt/telegram-ollama-bot:/app/data # Bind mount for config files to /app/data inside container

    # Default command to run the bot, relative to the WORKDIR
    # command: /bin/bash # TEMPORARY: For network debugging. Revert to default after debugging.
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Optional: Expose port if you want direct access
    # ports:
    #   - "8080:8080"

volumes:
  bot_logs:
    driver: local
